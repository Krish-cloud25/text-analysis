{"filter":false,"title":"wordcount_spark.py","tooltip":"/wordcount_spark.py","undoManager":{"mark":4,"position":4,"stack":[[{"start":{"row":0,"column":0},"end":{"row":27,"column":0},"action":"insert","lines":["from pyspark import SparkContext","import time","","start = time.time()","","sc = SparkContext(\"local[*]\", \"WordCount\")","sc.setLogLevel(\"ERROR\")","","# Load dataset (text file)","lines = sc.textFile(\"dataset_unzipped/SMSSpamCollection\")","","# MapReduce","word_counts = (","    lines.flatMap(lambda line: line.split())","         .map(lambda word: (word.lower(), 1))","         .reduceByKey(lambda a, b: a + b)",")","","# Print top 10","top_words = word_counts.takeOrdered(10, key=lambda x: -x[1])","for word, count in top_words:","    print(f\"{word}: {count}\")","","end = time.time()","print(f\"\\n[Parallel Spark] Completed in {end - start:.2f} seconds\")","","sc.stop()",""],"id":1}],[{"start":{"row":0,"column":0},"end":{"row":27,"column":0},"action":"remove","lines":["from pyspark import SparkContext","import time","","start = time.time()","","sc = SparkContext(\"local[*]\", \"WordCount\")","sc.setLogLevel(\"ERROR\")","","# Load dataset (text file)","lines = sc.textFile(\"dataset_unzipped/SMSSpamCollection\")","","# MapReduce","word_counts = (","    lines.flatMap(lambda line: line.split())","         .map(lambda word: (word.lower(), 1))","         .reduceByKey(lambda a, b: a + b)",")","","# Print top 10","top_words = word_counts.takeOrdered(10, key=lambda x: -x[1])","for word, count in top_words:","    print(f\"{word}: {count}\")","","end = time.time()","print(f\"\\n[Parallel Spark] Completed in {end - start:.2f} seconds\")","","sc.stop()",""],"id":2}],[{"start":{"row":0,"column":0},"end":{"row":41,"column":0},"action":"insert","lines":["from pyspark import SparkContext","import time","","# Measure execution time","start = time.time()","","# Create Spark context","sc = SparkContext(\"local[*]\", \"WordCount\")","sc.setLogLevel(\"ERROR\")","","# Read the dataset","print(\"[INFO] Reading file...\")","text_file = sc.textFile(\"dataset_unzipped/SMSSpamCollection\")","","# Preview sample","sample = text_file.take(5)","print(\"[DEBUG] Sample lines:\", sample)","","# Perform word count","print(\"[INFO] Performing word count...\")","counts = (","    text_file.flatMap(lambda line: line.split())","             .map(lambda word: (word.lower(), 1))","             .reduceByKey(lambda a, b: a + b)",")","","# Get top 10 words","print(\"[INFO] Extracting top 10...\")","top_10 = counts.takeOrdered(10, key=lambda x: -x[1])","","# Print results","print(\"\\n==== Top 10 Words ====\")","for word, count in top_10:","    print(f\"{word}: {count}\")","","# Execution time","end = time.time()","print(f\"\\n[Parallel Spark] Completed in {end - start:.2f} seconds\")","","# Stop Spark","sc.stop()",""],"id":3}],[{"start":{"row":0,"column":0},"end":{"row":41,"column":0},"action":"remove","lines":["from pyspark import SparkContext","import time","","# Measure execution time","start = time.time()","","# Create Spark context","sc = SparkContext(\"local[*]\", \"WordCount\")","sc.setLogLevel(\"ERROR\")","","# Read the dataset","print(\"[INFO] Reading file...\")","text_file = sc.textFile(\"dataset_unzipped/SMSSpamCollection\")","","# Preview sample","sample = text_file.take(5)","print(\"[DEBUG] Sample lines:\", sample)","","# Perform word count","print(\"[INFO] Performing word count...\")","counts = (","    text_file.flatMap(lambda line: line.split())","             .map(lambda word: (word.lower(), 1))","             .reduceByKey(lambda a, b: a + b)",")","","# Get top 10 words","print(\"[INFO] Extracting top 10...\")","top_10 = counts.takeOrdered(10, key=lambda x: -x[1])","","# Print results","print(\"\\n==== Top 10 Words ====\")","for word, count in top_10:","    print(f\"{word}: {count}\")","","# Execution time","end = time.time()","print(f\"\\n[Parallel Spark] Completed in {end - start:.2f} seconds\")","","# Stop Spark","sc.stop()",""],"id":4}],[{"start":{"row":0,"column":0},"end":{"row":42,"column":0},"action":"insert","lines":["from pyspark import SparkContext","import time","","# Measure execution time","start = time.time()","","# Create Spark context","sc = SparkContext(\"local[*]\", \"WordCount\")","sc.setLogLevel(\"ERROR\")","","# Read the large dataset","dataset_path = \"dataset_unzipped/SMSSpamCollection_large\"","print(f\"[INFO] Reading file: {dataset_path}\")","text_file = sc.textFile(dataset_path)","","# Preview sample","sample = text_file.take(3)","print(\"[DEBUG] Sample lines:\", sample)","","# Perform word count","print(\"[INFO] Performing word count...\")","counts = (","    text_file.flatMap(lambda line: line.split())","             .map(lambda word: (word.lower(), 1))","             .reduceByKey(lambda a, b: a + b)",")","","# Get top 10 words","print(\"[INFO] Extracting top 10 words...\")","top_10 = counts.takeOrdered(10, key=lambda x: -x[1])","","# Print results","print(\"\\n==== Top 10 Words (Spark Parallel) ====\")","for word, count in top_10:","    print(f\"{word}: {count}\")","","# Execution time","end = time.time()","print(f\"\\n[Parallel Spark] Completed in {end - start:.2f} seconds\")","","# Stop Spark","sc.stop()",""],"id":5}]]},"ace":{"folds":[],"scrolltop":67,"scrollleft":0,"selection":{"start":{"row":42,"column":0},"end":{"row":42,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1752091566311,"hash":"5e991643c0ad382dbf99d3e021856d9e996a9bba"}