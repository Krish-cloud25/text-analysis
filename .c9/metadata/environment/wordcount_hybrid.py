{"filter":false,"title":"wordcount_hybrid.py","tooltip":"/wordcount_hybrid.py","undoManager":{"mark":3,"position":3,"stack":[[{"start":{"row":0,"column":0},"end":{"row":33,"column":0},"action":"remove","lines":["import multiprocessing","import time","from collections import Counter","","# Split file into N chunks (simulate EC2 task distribution)","def process_chunk(chunk):","    words = chunk.lower().split()","    return Counter(words)","","if __name__ == \"__main__\":","    start = time.time()","","    with open(\"dataset_unzipped/SMSSpamCollection\", \"r\") as f:","        lines = f.readlines()","","    num_chunks = 4  # Simulate 4 EC2 instances","    chunk_size = len(lines) // num_chunks","    chunks = [ ''.join(lines[i*chunk_size:(i+1)*chunk_size]) for i in range(num_chunks) ]","","    with multiprocessing.Pool(num_chunks) as pool:","        counters = pool.map(process_chunk, chunks)","","    total_counter = Counter()","    for counter in counters:","        total_counter.update(counter)","","    top_10 = total_counter.most_common(10)","    print(\"==== Top 10 Words (Hybrid Parallelism) ====\")","    for word, count in top_10:","        print(f\"{word}: {count}\")","","    end = time.time()","    print(f\"\\n[Hybrid Parallel] Completed in {end - start:.2f} seconds\")",""],"id":5}],[{"start":{"row":0,"column":0},"end":{"row":40,"column":0},"action":"insert","lines":["import multiprocessing","import time","from collections import Counter","","# Simulated complex word processing logic","def process_chunk(chunk):","    # Artificial computation: simulate heavy processing logic","    time.sleep(1)  # simulate EC2 delay","    words = chunk.lower().split()","    words = [word + \"_extra\" for word in words]  # Simulated extra logic","    return Counter(words)","","if __name__ == \"__main__\":","    start = time.time()","","    print(\"[INFO] Reading large dataset...\")","    with open(\"dataset_unzipped/SMSSpamCollection_large\", \"r\") as f:","        lines = f.readlines()","","    print(\"[INFO] Splitting data for multiprocessing...\")","    num_chunks = 4  # Simulate 4 EC2 instances","    chunk_size = len(lines) // num_chunks","    chunks = [''.join(lines[i*chunk_size:(i+1)*chunk_size]) for i in range(num_chunks)]","","    print(\"[INFO] Starting multiprocessing pool...\")","    with multiprocessing.Pool(num_chunks) as pool:","        counters = pool.map(process_chunk, chunks)","","    print(\"[INFO] Aggregating results...\")","    total_counter = Counter()","    for counter in counters:","        total_counter.update(counter)","","    print(\"\\n==== Top 10 Words (Hybrid Parallelism) ====\")","    top_10 = total_counter.most_common(10)","    for word, count in top_10:","        print(f\"{word}: {count}\")","","    end = time.time()","    print(f\"\\n[Hybrid Parallel] Completed in {end - start:.2f} seconds\")",""],"id":6}],[{"start":{"row":0,"column":0},"end":{"row":40,"column":0},"action":"remove","lines":["import multiprocessing","import time","from collections import Counter","","# Simulated complex word processing logic","def process_chunk(chunk):","    # Artificial computation: simulate heavy processing logic","    time.sleep(1)  # simulate EC2 delay","    words = chunk.lower().split()","    words = [word + \"_extra\" for word in words]  # Simulated extra logic","    return Counter(words)","","if __name__ == \"__main__\":","    start = time.time()","","    print(\"[INFO] Reading large dataset...\")","    with open(\"dataset_unzipped/SMSSpamCollection_large\", \"r\") as f:","        lines = f.readlines()","","    print(\"[INFO] Splitting data for multiprocessing...\")","    num_chunks = 4  # Simulate 4 EC2 instances","    chunk_size = len(lines) // num_chunks","    chunks = [''.join(lines[i*chunk_size:(i+1)*chunk_size]) for i in range(num_chunks)]","","    print(\"[INFO] Starting multiprocessing pool...\")","    with multiprocessing.Pool(num_chunks) as pool:","        counters = pool.map(process_chunk, chunks)","","    print(\"[INFO] Aggregating results...\")","    total_counter = Counter()","    for counter in counters:","        total_counter.update(counter)","","    print(\"\\n==== Top 10 Words (Hybrid Parallelism) ====\")","    top_10 = total_counter.most_common(10)","    for word, count in top_10:","        print(f\"{word}: {count}\")","","    end = time.time()","    print(f\"\\n[Hybrid Parallel] Completed in {end - start:.2f} seconds\")",""],"id":7}],[{"start":{"row":0,"column":0},"end":{"row":65,"column":0},"action":"insert","lines":["import multiprocessing","import time","from collections import Counter","import boto3","","# Simulated complex word processing logic","def process_chunk(chunk):","    time.sleep(1)  # Simulate EC2 delay","    words = chunk.lower().split()","    words = [word + \"_extra\" for word in words]  # Simulate processing","    return Counter(words)","","if __name__ == \"__main__\":","    start = time.time()","","    print(\"[INFO] Reading large dataset...\")","    with open(\"dataset_unzipped/SMSSpamCollection_large\", \"r\") as f:","        lines = f.readlines()","","    print(\"[INFO] Splitting data for multiprocessing...\")","    num_chunks = 4  # Simulate 4 EC2 instances","    chunk_size = len(lines) // num_chunks","    chunks = [''.join(lines[i*chunk_size:(i+1)*chunk_size]) for i in range(num_chunks)]","","    print(\"[INFO] Starting multiprocessing pool...\")","    with multiprocessing.Pool(num_chunks) as pool:","        counters = pool.map(process_chunk, chunks)","","    print(\"[INFO] Aggregating results...\")","    total_counter = Counter()","    for counter in counters:","        total_counter.update(counter)","","    top_10 = total_counter.most_common(10)","    print(\"\\n==== Top 10 Words (Hybrid Parallelism) ====\")","    for word, count in top_10:","        print(f\"{word}: {count}\")","","    end = time.time()","    exec_time = end - start","    throughput = len(lines) / exec_time if exec_time > 0 else 0","","    print(f\"\\n[Hybrid Parallel] Completed in {exec_time:.2f} seconds\")","    print(f\"[INFO] Throughput: {throughput:.2f} records/second\")","","    # ===== Push to CloudWatch =====","    print(\"[INFO] Pushing metrics to CloudWatch...\")","    cloudwatch = boto3.client('cloudwatch', region_name='us-east-1')  # Adjust if needed","","    cloudwatch.put_metric_data(","        Namespace='MyApp/Performance',","        MetricData=[","            {","                'MetricName': 'ExecutionTime',","                'Value': exec_time,","                'Unit': 'Seconds'","            },","            {","                'MetricName': 'Throughput',","                'Value': throughput,","                'Unit': 'Count/Second'","            }","        ]","    )","    print(\"âœ… Metrics pushed to CloudWatch.\")",""],"id":8}]]},"ace":{"folds":[],"scrolltop":389,"scrollleft":0,"selection":{"start":{"row":65,"column":0},"end":{"row":65,"column":0},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":{"row":26,"state":"start","mode":"ace/mode/python"}},"timestamp":1752092342126,"hash":"d581861e75df05d27aa0b9d63d31e6ed67f768e8"}